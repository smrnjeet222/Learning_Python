{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch_Basics\n",
    "\n",
    "### pytorch tensors\n",
    "\n",
    "An short introduction about PyTorch and about the chosen functions. \n",
    "- torch.as_tensor()\n",
    "- torch.reshape()\n",
    "- torch.squeeze()\n",
    "- torch.t()\n",
    "- torch.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch and other required modules\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. torch.tensor() vs torch.as_tensor()\n",
    "\n",
    "Zero memory-copy (very efficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "d = np.array([[1,2], [3,4]])\n",
    " \n",
    "# factory f'n\n",
    "    \n",
    "t1 = torch.tensor(d)  \n",
    "t2 = torch.as_tensor(d)\n",
    "t3 = torch.from_numpy(d)\n",
    "\n",
    "t4 = torch.Tensor(d) # constructor\n",
    "\n",
    "print(t1)\n",
    "print(t4)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here,`torch.tensor()` and `torch.Tensor()` always creates copy of the data.<br>\n",
    "whereas, `torch.as_tensor()` and `torch.from_numpy()` shares the data d <br>\n",
    "        i.e. they don't create new m/o instead creates a pointer pointin to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[9, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[9, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "d[0][0] = 9\n",
    "\n",
    "print(t1)\n",
    "print(t4)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change the original data d , change is also reflected in t2 and t3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t4.dtype)\n",
    "t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice here, torch.Tensor is a constructor and <br>data passed was int32 but t4 dtype is float32.<br>\n",
    "\n",
    "torch.Tensor assigns data to default datatype i.e float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got list)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-f15c02c8c20b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m#list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtl1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: expected np.ndarray (got list)"
     ]
    }
   ],
   "source": [
    "dl = [[1,2],[3,4]]  #list\n",
    "\n",
    "tl1 = torch.from_numpy(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`torch.from_numpy()` function only accepts numpy.ndarrays, <br>while the `torch.as_tensor()` function accepts other variety too such as list.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl1 = torch.as_tensor(dl)\n",
    "tl1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. reshape()\n",
    "\n",
    "Changes shape of tensor to the specified shape but with the same data and number of elements as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 2\n",
      "no. of elems: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " t = torch.tensor([\n",
    "    [1,1,1,1],\n",
    "    [2,2,2,2],\n",
    "    [3,3,3,3]\n",
    "])\n",
    "\n",
    "print(f\"Rank: {len(t.shape)}\")    \n",
    "print(f\"no. of elems: {t.numel()}\")\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape of tensor and size is same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 2, 2],\n",
       "        [2, 2, 3, 3, 3, 3]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape([2,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 2, 2],\n",
       "        [2, 2, 3],\n",
       "        [3, 3, 3]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape([4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(1,-1)  # same as t.reshape([1,12]) , can use if 12 is unknown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1],\n",
       "         [1, 2, 2]],\n",
       "\n",
       "        [[2, 2, 3],\n",
       "         [3, 3, 3]]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(2,2,3) # can also increase the rank of tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While reshaping the tensor, data and no. of elements are same, just size is modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[3, 6]' is invalid for input of size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-ceebbda6f367>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[3, 6]' is invalid for input of size 12"
     ]
    }
   ],
   "source": [
    "t.reshape([3,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6x3 = 18 , therefore the tensor for size 12 can't be transformed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. squeeze()\n",
    "\n",
    "Squeezing a tensor removes the dimensions or axes that have a length of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.reshape(1,-1)\n",
    "print(t.shape)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this reshaping gives flattened tensor but rank is 2 and size(1,12)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = t.squeeze()\n",
    "print(t.shape)\n",
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with `squeeze()` rank/dimension is decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3]])\n",
      "tensor([[1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]])\n"
     ]
    }
   ],
   "source": [
    "print(tr.unsqueeze(dim=1))\n",
    "print(tr.unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`unsqueeze()` can be used to do revese i.e increasing the rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [2, 2],\n",
      "        [2, 2],\n",
      "        [3, 3],\n",
      "        [3, 3]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1],\n",
       "         [1, 1],\n",
       "         [2, 2],\n",
       "         [2, 2],\n",
       "         [3, 3],\n",
       "         [3, 3]]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = t.reshape([6,2])\n",
    "print(tr.squeeze())\n",
    "tr.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here there in no dimensions of length 1 so tensor size remains the same.<br>\n",
    "but, can be unsqueezed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. torch.t(x)\n",
    "\n",
    "Expects input to be <= 2-D tensor and transposes dimensions 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6578,  0.3057,  0.8777],\n",
       "        [-0.3586,  0.4123, -1.0336],\n",
       "        [-0.7004, -1.7553,  1.5306],\n",
       "        [-0.6648,  0.8039, -0.4013]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.randn()` Returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6578, -0.3586, -0.7004, -0.6648],\n",
       "        [ 0.3057,  0.4123, -1.7553,  0.8039],\n",
       "        [ 0.8777, -1.0336,  1.5306, -0.4013]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.t(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "returns the transpose of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8573, 0.2915, 0.8963, 0.1056],\n",
      "         [0.3040, 0.0852, 0.9746, 0.5156],\n",
      "         [0.0915, 0.5199, 0.6390, 0.9429]],\n",
      "\n",
      "        [[0.0931, 0.5485, 0.7476, 0.8499],\n",
      "         [0.2552, 0.5190, 0.1909, 0.0848],\n",
      "         [0.2000, 0.6600, 0.6962, 0.5286]]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "t() expects a tensor with <= 2 dimensions, but self is 3D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-d6b0d2f921d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: t() expects a tensor with <= 2 dimensions, but self is 3D"
     ]
    }
   ],
   "source": [
    "y = torch.rand(2,3,4)\n",
    "print(y)\n",
    "torch.t(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f'n breaks for tensor with dimensions > 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. torch.cat()\n",
    "\n",
    "Concatenates the given sequence of seq tensors in the given dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 4, 2],\n",
      "         [2, 0, 0]],\n",
      "\n",
      "        [[0, 2, 2],\n",
      "         [2, 4, 0]]])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[7, 2, 3],\n",
       "         [1, 1, 5]],\n",
       "\n",
       "        [[4, 3, 4],\n",
       "         [1, 6, 2]]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(5,(2,2,3))\n",
    "print(x)\n",
    "\n",
    "y = torch.randint(8,(2,2,3))\n",
    "print()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created 3 dimenssional tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 4, 2, 7, 2, 3],\n",
       "         [2, 0, 0, 1, 1, 5]],\n",
       "\n",
       "        [[0, 2, 2, 4, 3, 4],\n",
       "         [2, 4, 0, 1, 6, 2]]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x,y), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 4, 2],\n",
       "         [2, 0, 0],\n",
       "         [7, 2, 3],\n",
       "         [1, 1, 5],\n",
       "         [0, 4, 2],\n",
       "         [2, 0, 0]],\n",
       "\n",
       "        [[0, 2, 2],\n",
       "         [2, 4, 0],\n",
       "         [4, 3, 4],\n",
       "         [1, 6, 2],\n",
       "         [0, 2, 2],\n",
       "         [2, 4, 0]]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x,y,x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 4, 2],\n",
       "         [2, 0, 0]],\n",
       "\n",
       "        [[0, 2, 2],\n",
       "         [2, 4, 0]],\n",
       "\n",
       "        [[7, 2, 3],\n",
       "         [1, 1, 5]],\n",
       "\n",
       "        [[4, 3, 4],\n",
       "         [1, 6, 2]]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x,y), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we concatenate tensors, we increase the number of elements contained within the resulting tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x Rank: 3\n",
      "z Rank: 2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 3 and 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-722042aa0747>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x Rank:\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"z Rank:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 3 and 2"
     ]
    }
   ],
   "source": [
    "z = torch.randint(5,(2,3))\n",
    "print(\"x Rank:\" , len(x.shape))\n",
    "print(\"z Rank:\",len(z.shape))\n",
    "torch.cat((x,z), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensors having differnt dimensions can't be concatenated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concatenation is simillar like addition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook discusses some of the basic tensor functions which are usefull in modifications and further computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "Provide links to your references and other interesting articles about tensors\n",
    "* Official documentation for `torch.Tensor`: https://pytorch.org/docs/stable/tensors.html\n",
    "* This Article : https://deeplizard.com/learn/video/AglLTlms7HU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
